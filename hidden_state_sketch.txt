Outline of new algorithm.



/* summarizes basecall data at a locus.  Basecall counts are packed
into 12,10,6,4 bits (4096, 1024, 64, 16) */
#define N_MAX_QUAL_BINS 10
struct basecall_summary {
    unsigned n_qual_bins;
    uint32_t packed_counts[N_MAX_QUAL_BINS];
}

/* holds a distribution of weighted hidden counts */
#define N_HDIST_BASE 10
struct hidden_dist {
    unsigned n_extra; /* */
    struct {
        double prob;
        uint32_t count[4];
    } a[N_HDIST_BASE], *a_extra;
}


PRESCAN

1. Prescan input and accumulate a number of loci worth of binned
quality score counts, storing each as keys in a hash map.

2. At the end of this prescan, merge the thread-local hash maps
into a (to-be) readonly hash map of the same type.

3. Traversing the keys in n threads, take every nth + t entry and
run the algorithm for populating the value.  (an array of
weighted hidden base counts)

MAIN RUN

0. The read-only hash has been populated

1. Process a chunk of new data.
   a. Compute the pileup
   b. Compute the binned, ranked base-counts
   c. Pack counts into the key structure
   d. Sort the key structures
   e. Traverse sorted list of keys
      i)  if same as previous, 




Algorithm for estimating P(o, g(h))


1. Compute marginals in 2D simplex.
   a. compute 2D counts in each quality bin
   b. stepping towards the majority base one by one, compute the
      change in the joint score.
      1. add to path probability
      2. replace multinomial factor
      3. update or replace prior
   c. repeat step b until a peak is found.
   d. continue until the marginal prob is less than some fraction
      of the peak

2. Repeat the process in step 1 in 3D for each non-negligible 2D simplex point.
   a. Subdivide the non-majority counts in the 2D marginal into majority
      and non-majority counts.
   b. start at the point having 100% of non-majority base counts, stepping
      towards the non-majority direction, repeating steps in 1.

3. Recurse at each 3D point to 4D.


Details for step 1:

Define an estimation proceedure for Pr(o,F) as the sum over L of
Pr(o,L,F) starting with L at a minimum, and evaluating the Pr(o,L,F)
terms until they start to decline, and the next term is smaller than
some pre-defined fraction of the running sum.

This first type of 'step' involves two of the three factors being modified:

1. The MC factor changes.
2. The Path changes

For a given o, we would like to identify the set of values of F for
which Pr(o,F) is non-negligible.  To do this, we start with F equal to
O, and calculate Pr(o,L,F) for L = 0.  Then, increase L by 2 (adding
one miscall for each symbol in F) until Pr(o,L,F) is less than a
certain fraction of the original, and we know it is declining.

Then, choose F one step closer to the closest corner and compute
Pr(o,L,F) for minimal L, then lengthen L, etc.

Continue until we reach a peak value for some F and it starts to
decline.  Stop when the value of Pr(o,F)

In 2D, the MC factors can be precomputed to large depth.  10000 x 50
factors could be pre-computed.

The Path() factors could have up to 10000 x 100 x 8 = 8,000,000 (N x L
x e) distinct values.

The second type of 'step' involves moving from one F to another,
adjacent F.  If we first 

